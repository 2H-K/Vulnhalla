#!/usr/bin/env python3
"""
SARIF (Static Analysis Results Interchange Format) Parser.

This module provides functionality to:
1. Parse SARIF files generated by CodeQL
2. Extract data flow paths from SARIF results
3. Enrich issues with data flow information

SARIF is a standardized format for static analysis results that provides
rich context including complete data flow paths from source to sink.
"""

import json
import os
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union
from dataclasses import dataclass, field

# Try to use ijson for streaming parsing of large files
try:
    import ijson
    IJSON_AVAILABLE = True
except ImportError:
    IJSON_AVAILABLE = False
    import json as json_module

from src.utils.logger import get_logger
from src.utils.exceptions import CodeQLError

logger = get_logger(__name__)


@dataclass
class Location:
    """Represents a location in source code."""
    file_path: str
    start_line: int
    end_line: int
    start_column: int = 0
    end_column: int = 0
    message: str = ""
    
    def __str__(self) -> str:
        return f"{self.file_path}:{self.start_line}"


@dataclass
class FlowStep:
    """Represents a single step in a data flow path."""
    location: Location
    step_type: str  # 'source', 'sanitizer', 'sink', 'step'
    description: str = ""
    code_snippet: str = ""
    
    def format_for_prompt(self) -> str:
        """Format this flow step for inclusion in LLM prompt."""
        snippet_info = f"\n  Code: {self.code_snippet}" if self.code_snippet else ""
        return f"- [{self.step_type.upper()}] {self.location}{snippet_info}"


@dataclass
class DataFlowPath:
    """Represents a complete data flow path from source to sink."""
    rule_id: str
    rule_name: str
    severity: str
    message: str
    steps: List[FlowStep] = field(default_factory=list)
    
    @property
    def sources(self) -> List[FlowStep]:
        """Get source steps."""
        return [s for s in self.steps if s.step_type == 'source']
    
    @property
    def sinks(self) -> List[FlowStep]:
        """Get sink steps."""
        return [s for s in self.steps if s.step_type == 'sink']
    
    @property
    def sanitizers(self) -> List[FlowStep]:
        """Get sanitizer steps."""
        return [s for s in self.steps if s.step_type == 'sanitizer']
    
    def format_for_prompt(self) -> str:
        """Format the complete data flow path for LLM prompt."""
        if not self.steps:
            return "No data flow path available."
        
        header = f"=== Data Flow Analysis for {self.rule_name} ===\n"
        header += f"Message: {self.message}\n"
        header += f"Severity: {self.severity}\n\n"
        header += "Flow Path:\n"
        
        steps_str = "\n".join(step.format_for_prompt() for step in self.steps)
        
        return header + steps_str
    
    def get_summary(self) -> str:
        """Get a brief summary of the flow path."""
        source = self.sources[0] if self.sources else None
        sink = self.sinks[0] if self.sinks else None
        
        if source and sink:
            return f"Source: {source.location} â†’ Sink: {sink.location}"
        elif source:
            return f"Source: {source.location}"
        elif sink:
            return f"Sink: {sink.location}"
        return "No flow information"


class SarifParser:
    """
    SARIF format parser for extracting data flow paths.
    
    Supports both standard SARIF and CodeQL-specific SARIF extensions.
    """
    
    # SARIF severity mapping
    SEVERITY_MAP = {
        "error": "high",
        "warning": "medium",
        "note": "low",
        "none": "low"
    }
    
    def __init__(self, sarif_file: Optional[str] = None):
        """
        Initialize the SARIF parser.
        
        Args:
            sarif_file: Path to SARIF file (optional, can be loaded later).
        """
        self.sarif_file = sarif_file
        self.sarif_data: Optional[Dict[str, Any]] = None
        self._runs: List[Dict[str, Any]] = []
        
    def load_sarif(self, sarif_file: str) -> None:
        """
        Load SARIF file from disk.
        
        Args:
            sarif_file: Path to SARIF file.
            
        Raises:
            CodeQLError: If file cannot be read.
        """
        if not Path(sarif_file).exists():
            raise CodeQLError(f"SARIF file not found: {sarif_file}")
        
        self.sarif_file = sarif_file
        
        try:
            with open(sarif_file, 'r', encoding='utf-8') as f:
                # Use ijson for large files if available
                if IJSON_AVAILABLE:
                    # For now, still load full JSON as ijson parsing is more complex
                    self.sarif_data = json.load(f)
                else:
                    self.sarif_data = json.load(f)
        except json.JSONDecodeError as e:
            raise CodeQLError(f"Invalid JSON in SARIF file: {e}") from e
        except Exception as e:
            raise CodeQLError(f"Error reading SARIF file: {e}") from e
        
        # Extract runs
        self._runs = self.sarif_data.get('runs', [])
        logger.info(f"Loaded SARIF with {len(self._runs)} runs")
    
    def parse_results(self) -> List[DataFlowPath]:
        """
        Parse all results from SARIF data.
        
        Returns:
            List of DataFlowPath objects.
        """
        if not self.sarif_data:
            if self.sarif_file:
                self.load_sarif(self.sarif_file)
            else:
                return []
        
        paths = []
        
        for run in self._runs:
            # Parse results
            results = run.get('results', [])
            
            for result in results:
                flow_path = self._parse_result(result, run)
                if flow_path:
                    paths.append(flow_path)
        
        logger.info(f"Parsed {len(paths)} data flow paths")
        return paths
    
    def _parse_result(
        self,
        result: Dict[str, Any],
        run: Dict[str, Any]
    ) -> Optional[DataFlowPath]:
        """
        Parse a single SARIF result into a DataFlowPath.
        
        Args:
            result: SARIF result object.
            run: SARIF run object.
            
        Returns:
            DataFlowPath or None if parsing fails.
        """
        rule_id = result.get('ruleId', '')
        message = result.get('message', {}).get('text', '')
        
        # Get rule information
        rules = run.get('tool', {}).get('driver', {}).get('rules', {})
        rule_info = rules.get(rule_id, {})
        rule_name = rule_info.get('name', rule_id)
        severity = rule_info.get('defaultConfiguration', {}).get('level', 'warning')
        
        # Map severity
        mapped_severity = self.SEVERITY_MAP.get(severity, 'medium')
        
        # Parse code flow / data flow
        steps = self._parse_code_flows(result, run)
        
        if not steps:
            # Try to get location from result itself
            locations = result.get('locations', [])
            if locations:
                location = locations[0].get('physicalLocation', {})
                artifact = location.get('artifactLocation', {})
                region = location.get('region', {})
                
                loc = Location(
                    file_path=artifact.get('uri', 'unknown'),
                    start_line=region.get('startLine', 0),
                    end_line=region.get('endLine', 0),
                    start_column=region.get('startColumn', 0),
                    end_column=region.get('endColumn', 0),
                    message=message
                )
                steps = [FlowStep(
                    location=loc,
                    step_type='source',
                    description=message
                )]
        
        return DataFlowPath(
            rule_id=rule_id,
            rule_name=rule_name,
            severity=mapped_severity,
            message=message,
            steps=steps
        )
    
    def _parse_code_flows(
        self,
        result: Dict[str, Any],
        run: Dict[str, Any]
    ) -> List[FlowStep]:
        """
        Parse code flows from SARIF result.
        
        Args:
            result: SARIF result object.
            run: SARIF run object.
            
        Returns:
            List of FlowStep objects.
        """
        steps = []
        
        # Get code flows
        code_flows = result.get('codeFlows', [])
        
        # Get thread flow locations from first code flow
        if not code_flows:
            return steps
        
        # Look for threadFlows
        for code_flow in code_flows:
            thread_flows = code_flow.get('threadFlows', [])
            
            for thread_flow in thread_flows:
                locations = thread_flow.get('locations', [])
                
                for idx, loc_data in enumerate(locations):
                    step = self._parse_thread_flow_location(loc_data, run)
                    if step:
                        steps.append(step)
        
        # If no code flows, try alternative data flow representation
        if not steps:
            # Check for stack traces or other flow representations
            stacks = result.get('stacks', [])
            for stack in stacks:
                frames = stack.get('frames', [])
                for frame in frames:
                    step = self._parse_stack_frame(frame, run)
                    if step:
                        steps.append(step)
        
        return steps
    
    def _parse_thread_flow_location(
        self,
        loc_data: Dict[str, Any],
        run: Dict[str, Any]
    ) -> Optional[FlowStep]:
        """
        Parse a thread flow location into a FlowStep.
        
        Args:
            loc_data: Thread flow location data.
            run: SARIF run object.
            
        Returns:
            FlowStep or None.
        """
        # Get location info
        location = loc_data.get('location', {})
        physical = location.get('physicalLocation', {})
        
        artifact = physical.get('artifactLocation', {})
        region = physical.get('region', {})
        
        file_path = artifact.get('uri', 'unknown')
        start_line = region.get('startLine', 0)
        end_line = region.get('endLine', 0)
        start_col = region.get('startColumn', 0)
        end_col = region.get('endColumn', 0)
        
        # Get message
        message = location.get('message', {}).get('text', '')
        
        loc = Location(
            file_path=file_path,
            start_line=start_line,
            end_line=end_line,
            start_column=start_col,
            end_column=end_col,
            message=message
        )
        
        # Determine step type from location properties
        step_type = self._determine_step_type(loc_data)
        
        # Get code snippet from source if available
        snippet = self._extract_snippet(run, file_path, start_line)
        
        return FlowStep(
            location=loc,
            step_type=step_type,
            description=message,
            code_snippet=snippet
        )
    
    def _parse_stack_frame(
        self,
        frame: Dict[str, Any],
        run: Dict[str, Any]
    ) -> Optional[FlowStep]:
        """
        Parse a stack frame into a FlowStep.
        
        Args:
            frame: Stack frame data.
            run: SARIF run object.
            
        Returns:
            FlowStep or None.
        """
        location = frame.get('location', {})
        physical = location.get('physicalLocation', {})
        
        artifact = physical.get('artifactLocation', {})
        region = physical.get('region', {})
        
        file_path = artifact.get('uri', 'unknown')
        start_line = region.get('startLine', 0)
        end_line = region.get('endLine', 0)
        
        message = location.get('message', {}).get('text', '')
        
        loc = Location(
            file_path=file_path,
            start_line=start_line,
            end_line=end_line,
            message=message
        )
        
        snippet = self._extract_snippet(run, file_path, start_line)
        
        return FlowStep(
            location=loc,
            step_type='step',
            description=message,
            code_snippet=snippet
        )
    
    def _determine_step_type(self, loc_data: Dict[str, Any]) -> str:
        """
        Determine the step type based on location properties.
        
        Args:
            loc_data: Location data.
            
        Returns:
            Step type string.
        """
        # Check for various SARIF properties that indicate step type
        properties = loc_data.get('properties', {})
        
        # CodeQL-specific properties
        if properties.get('isSource'):
            return 'source'
        if properties.get('isSink'):
            return 'sink'
        if properties.get('isSanitizer'):
            return 'sanitizer'
        
        # Check for category in message
        message = loc_data.get('location', {}).get('message', {}).get('text', '').lower()
        
        if 'source' in message or 'input' in message:
            return 'source'
        elif 'sanitiz' in message or 'check' in message:
            return 'sanitizer'
        elif 'sink' in message or 'vulnerab' in message:
            return 'sink'
        
        return 'step'
    
    def _extract_snippet(
        self,
        run: Dict[str, Any],
        file_path: str,
        line: int,
        context_lines: int = 2
    ) -> str:
        """
        Extract code snippet from SARIF artifacts.
        
        Args:
            run: SARIF run object.
            file_path: File path to extract from.
            line: Line number.
            context_lines: Number of context lines to include.
            
        Returns:
            Code snippet string.
        """
        # Get artifacts
        artifacts = run.get('artifacts', [])
        
        # Find matching artifact
        for artifact in artifacts:
            if artifact.get('location', {}).get('uri') == file_path:
                # Check for embedded content
                content = artifact.get('contents', {}).get('text')
                if content:
                    lines = content.split('\n')
                    start = max(0, line - context_lines - 1)
                    end = min(len(lines), line + context_lines)
                    
                    snippet_lines = lines[start:end]
                    return '\n'.join(f"{start + i + 1}: {l}" for i, l in enumerate(snippet_lines))
        
        return ""
    
    def enrich_issue(
        self,
        issue: Dict[str, str],
        flow_path: DataFlowPath
    ) -> Dict[str, str]:
        """
        Enrich an issue dictionary with data flow path information.
        
        Args:
            issue: Issue dictionary from CSV parsing.
            flow_path: Data flow path from SARIF.
            
        Returns:
            Enriched issue dictionary.
        """
        issue['data_flow'] = {
            'rule_id': flow_path.rule_id,
            'rule_name': flow_path.rule_name,
            'severity': flow_path.severity,
            'message': flow_path.message,
            'sources': [s.location.file_path + ':' + str(s.location.start_line) 
                       for s in flow_path.sources],
            'sinks': [s.location.file_path + ':' + str(s.location.start_line) 
                     for s in flow_path.sinks],
            'sanitizers': [s.location.file_path + ':' + str(s.location.start_line) 
                          for s in flow_path.sanitizers],
            'flow_summary': flow_path.get_summary()
        }
        
        # Add data flow message to issue
        issue['data_flow_message'] = flow_path.format_for_prompt()
        
        return issue
    
    def get_issues_by_rule(self, rule_id: str) -> List[DataFlowPath]:
        """
        Get all data flow paths for a specific rule.
        
        Args:
            rule_id: Rule ID to filter by.
            
        Returns:
            List of matching DataFlowPath objects.
        """
        all_paths = self.parse_results()
        return [p for p in all_paths if p.rule_id == rule_id]


class SarifPathEnricher:
    """
    Helper class to enrich prompts with SARIF data flow paths.
    """
    
    @staticmethod
    def format_flow_path_for_prompt(flow_path: DataFlowPath) -> str:
        """
        Format a data flow path for inclusion in LLM prompt.
        
        Args:
            flow_path: Data flow path to format.
            
        Returns:
            Formatted string for prompt.
        """
        return flow_path.format_for_prompt()
    
    @staticmethod
    def extract_key_locations(flow_path: DataFlowPath) -> Dict[str, Any]:
        """
        Extract key locations from a data flow path.
        
        Args:
            flow_path: Data flow path.
            
        Returns:
            Dictionary with source, sink, and sanitizer locations.
        """
        return {
            'source': flow_path.sources[0].location if flow_path.sources else None,
            'sink': flow_path.sinks[0].location if flow_path.sinks else None,
            'sanitizers': [s.location for s in flow_path.sanitizers],
            'all_steps': [s.location for s in flow_path.steps]
        }
    
    @staticmethod
    def create_flow_prompt_section(
        flow_path: DataFlowPath,
        include_code: bool = True
    ) -> str:
        """
        Create a prompt section describing the data flow.
        
        Args:
            flow_path: Data flow path.
            include_code: Whether to include code snippets.
            
        Returns:
            Formatted prompt section.
        """
        section = f"## Data Flow Analysis\n\n"
        section += f"**Rule**: {flow_path.rule_name} ({flow_path.rule_id})\n"
        section += f"**Severity**: {flow_path.severity.upper()}\n\n"
        section += f"**Issue**: {flow_path.message}\n\n"
        
        if flow_path.steps:
            section += "### Flow Path\n\n"
            
            for i, step in enumerate(flow_path.steps, 1):
                section += f"**Step {i}** [{step.step_type.upper()}]\n"
                section += f"  Location: {step.location.file_path}:{step.location.start_line}\n"
                
                if step.description:
                    section += f"  Description: {step.description}\n"
                
                if include_code and step.code_snippet:
                    section += f"  Code:\n"
                    for line in step.code_snippet.split('\n'):
                        section += f"    {line}\n"
                
                section += "\n"
        
        return section
